---
show: step
version: 1.0
enable_checker: true
---

# 爬取百度
## 回忆
- 这次真的爬了一个网站
	- oeasy.org
- 右键检查元素
	- 获取xpath
- 爬取之后获得属性href的值
- 然后切片并拼接为绝对链接地址
- 并且把每一个链接都爬了一遍
- 能出去爬个百度么？🤔

### 确认上网

- 一般的实验楼注册会员是不能上baidu之类的网站的
- 想要爬取百度有两种解决办法
	- 花钱成为会员
	- 在自己能上网的机器上使用火狐和python
- 想要爬百度
- 首先要确认能上百度

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635045425558)

### 准备环境

- 导入了该导入了包
- 然后发送请求
- 结果百度好像异常简单

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635045479631)

- 百度本身就是个大爬虫
- 他发现了我们是爬虫
- 结果就把我们给禁了😰
- 那怎么办？😱

### 假装

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635046905973)

- 然后把这个key-value对写到header中

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047188733)

- 注意headers是一个字典
	- key-value之间有冒号
	- key和value都有双引号包裹
	- 冒号双引号都是半角的
- 请求中的协议是https
- 好像可以得到正确的响应

### 生成etree

- 这下把正确的响应放到lxml中进行解析
- 生成一棵etree

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047598112)

- 但是得到的这一棵树
- 我怎样才能找到相应的内容呢
- 这就需要xpath

### 找xpath

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047760757)

- 右键左上角的新闻
	- 检查元素
- 可以看到他对应着a标签
- 后面的地图之类的也对应着a标签
- 如何得到xpath呢？

### 得到xpath

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047839977)

- 右键元素可以找到他对应的xpath
	- /html/body/div[1]/div[1]/div[3]/a[1]
	- 我们想要得到所有的a标签
	- /html/body/div[1]/div[1]/div[3]/a

### 筛选元素

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047975898)

- 我们可以得到一个a元素的列表
- 我们遍历这个列表

### 遍历列表

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048067904)

- 如果我想把链接也输出
- 应该怎么办？

### 输出连接

- 先查一下文档

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048399340)

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048417860)

- 遍历完成
- 这很简单
- 我们再看看百度热搜

### 百度热搜

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048555965)

- xpath是
	- /html/body/div[1]/div[1]/div[5]/div/div/div[3]/ul/li[1]/a/span[2]
	- 通过观察
	- 相关的列表对应的xpath应该是
		- /html/body/div[1]/div[1]/div[5]/div/div/div[3]/ul/li/a/span[2]

### 进行遍历

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048757888)

- 但是我如果想要同时输出具体链接呢？

### 重新构造列表

- span在a里面
- 所以我们先把所有的a的列表拿到
- 然后再使用下表的方式找到span的text

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635049094363)

- 还可以遍历最下面的链接吗？

### 最下面的

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635049252958)

- 这个好像比较简单
- 文字和链接都在a元素中

### xpath

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635049346923)

- a元素在p元素中
- 所以把p元素的索引去掉
- /html/body/div[1]/div[1]/div[7]/div/p/a

### 遍历

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635049450518)



### 总结

- 这次爬了baidu.com
- 找到了三组链接
- 然后分别遍历	
- 还可以爬点什么？🤔
- 下次再说
