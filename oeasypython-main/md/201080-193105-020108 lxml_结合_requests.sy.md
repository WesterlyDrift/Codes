---
show: step
version: 1.0
enable_checker: true
---

# 语法 html 生成
## 回忆

- 终于可以通过字符串构建一棵etree了
- 通过etree.HTML()函数将网页源文件进行parse(语法分析)生成一棵etree
- 通过etree.HTMLParser()函数设置parser
		- parser = etree.HTMLParser(remove_blank_text=True)
	- 用parser作为生成树的时候的参数
			- root = etree.HTML("<root>  <a/>   <b>  </b>     </root>", parser)
	- parser可以控制语法
- etee.indent()函数可以控制etree输出的缩进
	- etree.indent(root, space="\t")
	- etree.tostring(root)
- 我能用前面的requests爬到的字符串生成etree元素么？
	- 通过request获得网页源文件
	- 通过etree把源文件转化为一棵etree的元素树
- 就是把
	- request得到的response的content
	- 当做etree.HTML()需要的参数
	- 对接起来，可以么？🤔
- 还记得那个网页文件怎么来的么？
- oeasy.html

### 准备环境

- 把github上的网页素材拷贝下来
- 并放到合适位置

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211017-1634439171366)

- 启动nginx
- 浏览器中确认

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211017-1634435068115)t

### 整合
- requests

```python
import requests
response = requests.get("http://localhost/oeasy.html")
b_html = response.content
s_html = response.text
```

### etree

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211017-1634436427443)

- 其实仔细看可以发现broken_html 其实是混乱的html源代码
- 缺少一些结束标签
- 但是并不妨碍我们生成一棵完成的etree
- 这个事情就是libxml2.6.21 以上的库帮助我们完成的
- 包括补充头尾标签

### 整合

```
import requests
from lxml import etree
response = requests.get("http://localhost/oeasy.html")
s_html = response.text
et_html = etree.HTML(s_html)
print(etree.tostring(et_html,pretty_print=True).decode("utf-8"))
```



### 效果如何呢？
![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211017-1634439859969)

- 我倒是可以生成etree了
- 但是整个网页都下来了
- 我需要的只是其中的三种食物
	- 豆汁
	- 折耳根
	- 羊瘪汤
- 如何筛选呢？
- xpath

### 回忆xpath

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210901-1630506661307)

```python
build_text_list = etree.XPath("//text()") # lxml.etree only!
print(build_text_list(et_html))
```



### 尝试选择

```python
import requests
from lxml import etree
response = requests.get("http://localhost/oeasy.html")
s_html = response.text
et_html = etree.HTML(s_html)
food = et_html.xpath("/html/body/ul/li")
print(type(food))
print(food)
```

- xpath选择的是
- html下面的
- body下面的
- ul下面的li

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211017-1634446900421)

- 确实找到了一个列表
- 这个列表里包含三个li

### 乘胜追击

```python
from lxml import etree
response = requests.get("http://localhost/oeasy.html")
s_html = response.content
et_html = etree.HTML(s_html)
food = et_html.xpath("//html/body/ul/li")
print(food)
for element in food:
    print(element.text)
```

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211017-1634446957236)

- 试验成功
- 把这个东西写成一个py文件

### py文件

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210901-1630507176668)

## 总结

- 把前面的requests和这个etree结合了
	- 通过request获得网页的response
	- etree通过HTML函数把他转化为一棵etree树
	- 通过xpath筛选出节点
	- 通过循环遍历节点进行输出
- 流程跑起来了
- 但是这个xpath有点复杂
- 要从头到尾写得这么麻烦么？
- 有什么技巧吗么？🤔
- 下次再说
